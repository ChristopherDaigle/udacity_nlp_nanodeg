{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4fdbdd-4400-4e46-a260-63265cb54253",
   "metadata": {},
   "source": [
    "# Sequence to Sequence (Seq2Seq)\n",
    "\n",
    "Hello! For this next section, I'd like to introduce you to Jay Alammar. Jay has done some great work in interactive explorations of neural networks. If you haven't already, make sure you check out [his blog.](http://jalammar.github.io/)\n",
    "\n",
    "Jay will be teaching you about a particular RNN architecture called \"sequence to sequence\". In this case, you feed in a sequence of data and the network will output another sequence. This is typically used in problems such as machine translation, where you'd feed in a sentence in English and get out a sentence in Arabic.\n",
    "\n",
    "Sequence to sequence will prepare you for the next section, **Deep Learning Attention**, also taught by Jay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02410fc6-8143-4042-8164-520d71ddf87b",
   "metadata": {},
   "source": [
    "# <a id='0'>0: Introduction</a>\n",
    "\n",
    "We've known that we can do simple sentiment analysis using normal feedforward neural networks the network is able to learn how positive or negative each word is and can if a sequence as a whole has positive or negative things to say about its subject. However, we start running issues when we want to do a little bit more advanced models that deal with language and sequential data. Let's look at an example in the video.\n",
    "\n",
    "<img src=\"assets/images/05/img_001.png\" width=700 align='center'>\n",
    "\n",
    "Given the two sentences, if we wanted to find the year:\n",
    "> I went to Nepal in **2009**<br>\n",
    "> In **2009**, I went to Nepal\n",
    "\n",
    "If we used a typical feedforward network, it would have to have separate parameters for each input feature (i.e., every word). Technically, it would have to learn all the rules of language separately at each position in the input sentence.\n",
    "\n",
    "Recurrent nets are a powerful class of neural nets that deal with sequential data. They are especially suited for language and translation tasks because they can extend to sequences of any length. More importantly, they share parameters across different time steps. When they do learn a language model, they do it more efficiently than a traditional feed-forward network would.\n",
    "\n",
    "<img src=\"assets/images/05/img_002.png\" width=700 align='center'>\n",
    "\n",
    "**Sequential data** can refer to the input to the model, the output of the model, or both. The above image demonstrates different kinds of RNNs that are suited for different types of tasks.\n",
    "\n",
    "* many-to-one: reads a **sequence** of words and outputs a single value<br>\n",
    "> input: sequential<br>\n",
    "> output: singular<br>\n",
    "* many-to-many: reads a sequence of words and outputs a sequence of words<br>\n",
    "> input: sequential<br>\n",
    "> output: sequential<br>\n",
    "\n",
    "In the second *many-to-many* option, we are using a single RNN where we are forced to ouput at most as many vectors as we input. But that wouldn't work well for a chatbot where we would like the outcome to be unlimited in the length of items it returns. We want the model to take in the entire input before we start generating a response.\n",
    "\n",
    "In the first *many-to-many* option, it is composed of two RNNs that can map a sequence of any length to another sequence of any length. The basic premise is that we use two RNNs, an input (encoder network) and an output (decoder network), where the first reads the input sequence and the second generates the output sequence. It does this by the encoder handing what it learned to the decoder network.\n",
    "\n",
    "<img src=\"assets/images/05/img_003.png\" width=700 align='center'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29d33b-5b8e-4827-85d1-dd4f0a365c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_keras",
   "language": "python",
   "name": "venv_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
