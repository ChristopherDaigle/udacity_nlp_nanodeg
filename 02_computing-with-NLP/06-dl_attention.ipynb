{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194952ff-5c29-46d7-be7f-bbeb2af15a7e",
   "metadata": {},
   "source": [
    "# Introduction to Attention\n",
    "<!-- estimated time: 4hours -->\n",
    "\n",
    "This section will cover:\n",
    "\n",
    "* Sequence to sequence recap\n",
    "* Attention overview - Encoding\n",
    "* Attention overview - Decoding\n",
    "* Attention encoder\n",
    "* Attention decoder\n",
    "* Attention encoder & decoder\n",
    "* Bahdanau and Luong attention\n",
    "* Multiplicative attention\n",
    "* Additive attention\n",
    "* Computer vision applications\n",
    "* NLP application: Google neural machine translation\n",
    "* Other attention methods\n",
    "* The transformer and self-attention\n",
    "* Lab: Attention basics\n",
    "\n",
    "Attention started out in the field of computer vision as an attempt to mimic human perception:\n",
    "> \"One important property of human percetption is that one does not tend to process a while in its entirety at once. Instead, humans focus attention selectively on parts of the visual space to acquire information when and where it is needed, and combine information from different fixations over time to build up an internal representation of the scene, guiding future eye movements and decision making\"\n",
    "- [Recurrent Models of Visual Attention](https://arxiv.org/abs/1406.6247)\n",
    "\n",
    "Note here that instead of processing the entirety of the image, all that is needed to know it is a picture of a bird is to ignore the background and instead focus on the item of interest. Further, if we can separate attention from the entirety of the image to componenets of it, we can describe the image in a more complete and nuanced manner:\n",
    "<img src=\"assets/images/06/img_001.png\" width=700 align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c63eca-d6d7-48fb-af48-e7e406a86e5c",
   "metadata": {},
   "source": [
    "# 1: Seq2Seq Recap\n",
    "\n",
    "Classic, i.e., those without attention, Seq2Seq models have to look at the original sentence that is to be translated one time and then use that *entire* input to produce every single small output term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc26137-8d57-4039-841e-c0acfbf7bc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud_nlp",
   "language": "python",
   "name": "venv_ud_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
