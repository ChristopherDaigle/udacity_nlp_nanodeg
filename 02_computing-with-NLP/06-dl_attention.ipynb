{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194952ff-5c29-46d7-be7f-bbeb2af15a7e",
   "metadata": {},
   "source": [
    "# Introduction to Attention\n",
    "\n",
    "This section will cover:\n",
    "\n",
    "* Sequence to sequence recap\n",
    "* Attention overview - Encoding\n",
    "* Attention overview - Decoding\n",
    "* Attention encoder\n",
    "* Attention decoder\n",
    "* Attention encoder & decoder\n",
    "* Bahdanau and Luong attention\n",
    "* Multiplicative attention\n",
    "* Additive attention\n",
    "* Computer vision applications\n",
    "* NLP application: Google neural machine translation\n",
    "* Other attention methods\n",
    "* The transformer and self-attention\n",
    "* Lab: Attention basics\n",
    "\n",
    "<!-- <img src=\"assets/images/05/img_001.png\" width=700 align='center'> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49873525-0477-47a9-918d-7c14478c6c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud_nlp",
   "language": "python",
   "name": "venv_ud_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
